{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set display options \n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in combined csv file\n",
    "df = pd.read_csv('./data/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29928, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             REQUEST FOR INFORMATION - NEW DESIGN BOOKLET DIE CUTTING INSERT ASSEMBLY\n",
       "1                                 Audiovisual Suite for Large Auditorium - Maxwell AFB\n",
       "2                                                             Metrology Equipment Move\n",
       "3                                                    INNER INFLATABLE ASSY (LPU-36A/P)\n",
       "4                                                                           17--CRADLE\n",
       "5                                                              43--FILTER ELEMENT,FLUI\n",
       "6                                                              61--CABLE ASSEMBLY,SPEC\n",
       "7                                                              30--GEAR SET,SPUR,MATCH\n",
       "8                                                              53--NUT,SELF-LOCKING,EX\n",
       "9                                            6640--Notice of Intent to Sole Source    \n",
       "10                                                         Residual Leukocyte Counters\n",
       "11                                         FIRE DOOR LATCH ASSEMBLIES - USNS BRUNSWICK\n",
       "12                                                             61--CABLE ASSEMBLY,SPEC\n",
       "13                                                             43--FILTER ELEMENT,FLUI\n",
       "14    G001--502-20-3-169-0017 BPA MORTUARY AFFAIRS UNCLAIMED VETERAN BURIAL SERVICE   \n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect title column\n",
    "\n",
    "df['title'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29913                                                                                                                                                                                                             QUARTERLY REQUIREMENTS, BREAD, 2ND QTR., FY 2020\n",
       "29914                                                                                                                                                                    R--Request for Quotation (RFQ) Certified Industrial Hygienist Air Quality Survey Services\n",
       "29915                                                                                                                                                                                                                                           FITTING ASSY, FUEL\n",
       "29916                                                                                                                                                                                                             Weapons and Systems Integration Support Services\n",
       "29917                                                                                      AWARD A 1GB ETHERNET CONNECTION (RATE LIMIT TO 500MB) FROM 1 LINSLEY DR, PLAINVILLE, CT 06062 TO 77 GRAYLING AVENUE, NEW LONDON NAVAL SUBMARINE BASE, GROTON, CT 06349.\n",
       "29918                                                                              Award of a 1 GB ETHERNET FROM (BLDG) 261; (RM) 211; (FL) 2ND; 2308 FLORIDA KEYS AVE, TAMPA, FL, 33621, US TO  (BLDG) 500; (RM) 703; (FL) 7; 500 EAST ZACK ST; TAMPA, FL, 33602.\n",
       "29919                                                                                                                                                                                                                                 Dry Goods/Meats 2nd Qtr FY20\n",
       "29920                                           SUBMIT A QUOTE TO PROVIDE, INSTALL, AND MAINTAIN A 1GB ETHERNET SERVICE AT (BLDG) 1415; (RM) BCO/TELCO; 7177 LANGLEY STREET, MILTON, FL 32570 AND BLDG 90215; DCO ROOM; 306 CODY AVENUE, HURLBURT FIELD, FL 32544.\n",
       "29921                                                                                                                                                                                                                                 Purchase of Gearbox Assembly\n",
       "29922    SUBMIT A QUOTE TO PROVIDE, INSTALL, AND MAINTAIN A 10GB ETHERNET OVER OTN (OTU-2) COMMERCIAL LEASE BETWEEN NAS JOINT RESERVE BASE NEW ORLEANS, 400 RUSSELL AVENUE, NEW ORLEANS, LA, 70143 AND 712 CHAPPIE JAMES AVENUE, KEESLER AIR FORCE BASE, MS 39534.\n",
       "29923                                                                                                                                                                                                Remediation Services at the PR-58 Site in North Kingstown, RI\n",
       "29924               SUBMIT A QUOTE TO PROVIDE, INSTALL, AND MAINTAIN A 10GBE (GIGABIT ETHERNET) OVER OTN (OTU-2) COMMERCIAL LEASE BETWEEN NAS JOINT RESERVE BASE NEW ORLEANS 400 RUSSELL AVENUE, NEW ORLEANS, LA, AND 3326 GENERAL HUDNELL DRIVE, SAN ANTONIO, TX.\n",
       "29925                                 PROVIDE, INSTALL, AND MAINTAIN A 2.488GB (OC48C) BETWEEN BLDG 3782, RM174, FL: 1, 1000 CHIEFâ€™S WAY, CORRY STATION, PENSACOLA, FL  32511, AND BLDG 9357, RM 116, FL: 1, 8357 CYPRESS LOOP RD., STENNIS SPACE CENTER, MS 39529\n",
       "29926                                                                                                                                                                                                        J--REPLACE VICTORIAN PARK LIGHT FIXTURES AT: SF Marit\n",
       "29927                                                                                                                                                                                                                                                         COHO\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tokenize a column\n",
    "\n",
    "def tokenizer_function(column):\n",
    "    \"\"\"\n",
    "    Takes in a text column\n",
    "        tokenizes the text in each row\n",
    "        using pattern [[a-zA-Z]\\w+]\n",
    "        which matches every lowercase and upperase character between a-z that are word characters\n",
    "    Returns list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    # instantiate empty list of tokenized text\n",
    "    texts = []\n",
    "    \n",
    "    # instantiate tokenizer\n",
    "    tokenizer = RegexpTokenizer('[a-zA-Z]\\w+')\n",
    "    \n",
    "    # create for loop to tokenize each row and add the list of tokens to texts\n",
    "    for text in column:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "        # transform tokens into lower case strings\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        texts.append(tokens)\n",
    "    return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                           [request, for, information, new, design, booklet, die, cutting, insert, assembly]\n",
       "1                                                                                                                                                                                                  [audiovisual, suite, for, large, auditorium, maxwell, afb]\n",
       "2                                                                                                                                                                                                                                [metrology, equipment, move]\n",
       "3                                                                                                                                                                                                                              [inner, inflatable, assy, lpu]\n",
       "4                                                                                                                                                                                                                                                    [cradle]\n",
       "                                                                                                                                 ...                                                                                                                         \n",
       "29923                                                                                                                                                                                    [remediation, services, at, the, pr, site, in, north, kingstown, ri]\n",
       "29924    [submit, quote, to, provide, install, and, maintain, gbe, gigabit, ethernet, over, otn, otu, commercial, lease, between, nas, joint, reserve, base, new, orleans, russell, avenue, new, orleans, la, and, general, hudnell, drive, san, antonio, tx]\n",
       "29925                                                                     [provide, install, and, maintain, gb, oc48c, between, bldg, rm174, fl, chief, way, corry, station, pensacola, fl, and, bldg, rm, fl, cypress, loop, rd, stennis, space, center, ms]\n",
       "29926                                                                                                                                                                                              [replace, victorian, park, light, fixtures, at, sf, marit]\n",
       "29927                                                                                                                                                                                                                                                  [coho]\n",
       "Length: 29928, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call tokenizer function on df['title']\n",
    "\n",
    "tokenizer_function(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
